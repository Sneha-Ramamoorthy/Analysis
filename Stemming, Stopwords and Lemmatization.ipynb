{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJr8sgOSvCK7vg7zCneADc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sneha-Ramamoorthy/Analysis/blob/main/Stemming%2C%20Stopwords%20and%20Lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stopwords and** **Tokenization**"
      ],
      "metadata": {
        "id": "_xcQ_fLKM1OC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSTSdTl6Ej2v",
        "outputId": "0fc66827-8e68-46bc-c61c-08cac764d634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'am', 'Happy']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "#Download Stopwords data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "sent = \"I am Happy\"\n",
        "tokens = word_tokenize(sent)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sample_text = \"stopwords are common words used in text mining and Natural Language processing\"\n",
        "tokens = word_tokenize(Sample_text)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGbAA96KFixP",
        "outputId": "54931014-a6b2-4f0e-a389-b492a62332cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stopwords',\n",
              " 'are',\n",
              " 'common',\n",
              " 'words',\n",
              " 'used',\n",
              " 'in',\n",
              " 'text',\n",
              " 'mining',\n",
              " 'and',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'processing']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "7ogbFzpCHT_z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]"
      ],
      "metadata": {
        "id": "KSRxlhv6IZ8g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4AiVGnCIh8i",
        "outputId": "efe60a75-e341-44e1-b177-c97f89a31b4b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stopwords',\n",
              " 'common',\n",
              " 'words',\n",
              " 'used',\n",
              " 'text',\n",
              " 'mining',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'processing']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**"
      ],
      "metadata": {
        "id": "sUtmirtKMxZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "jZlmO42eJYUj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtA5Rr7WJhRG",
        "outputId": "abe39e81-3b8b-4ec9-8cc0-b78d95b61f8c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stopwords',\n",
              " 'are',\n",
              " 'common',\n",
              " 'words',\n",
              " 'used',\n",
              " 'in',\n",
              " 'text',\n",
              " 'mining',\n",
              " 'and',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'processing']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Porter = PorterStemmer()"
      ],
      "metadata": {
        "id": "vUDl777UJobs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Stemmed_words = [Porter.stem(word)for word in tokens]"
      ],
      "metadata": {
        "id": "TJmlE8dEJw5L"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te7a1bh7KITp",
        "outputId": "cb61cef4-1f7a-43e2-84e9-3f14b9f8216c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stopword',\n",
              " 'are',\n",
              " 'common',\n",
              " 'word',\n",
              " 'use',\n",
              " 'in',\n",
              " 'text',\n",
              " 'mine',\n",
              " 'and',\n",
              " 'natur',\n",
              " 'languag',\n",
              " 'process']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmitization**"
      ],
      "metadata": {
        "id": "z6WKWJ9fMqYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R3zCCCPKVNM",
        "outputId": "cf06311d-44d0-49b1-dbc2-b51f35107ab0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdrpxoXaKzNS",
        "outputId": "74487f08-7ec7-4694-af05-7e34895ca5d5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stopwords',\n",
              " 'are',\n",
              " 'common',\n",
              " 'word',\n",
              " 'used',\n",
              " 'in',\n",
              " 'text',\n",
              " 'mining',\n",
              " 'and',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'processing']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POS** **Tagging**"
      ],
      "metadata": {
        "id": "Yi9sD8xqK_VV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "from nltk import pos_tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cCRJocfK-62",
        "outputId": "c5297c76-ad2a-47ed-ea02-1aa0817e9216"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9QzWKnBLXzT",
        "outputId": "aa7cfa86-d8c0-4f31-e43f-135ba9eac4d1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stopwords',\n",
              " 'are',\n",
              " 'common',\n",
              " 'words',\n",
              " 'used',\n",
              " 'in',\n",
              " 'text',\n",
              " 'mining',\n",
              " 'and',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'processing']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in tokens:\n",
        "  print(nltk.pos_tag([word]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-wHmg7cLhBC",
        "outputId": "df3d03a0-aa9b-47be-92fc-8c2d007cff4b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('stopwords', 'NNS')]\n",
            "[('are', 'VBP')]\n",
            "[('common', 'JJ')]\n",
            "[('words', 'NNS')]\n",
            "[('used', 'VBN')]\n",
            "[('in', 'IN')]\n",
            "[('text', 'NN')]\n",
            "[('mining', 'NN')]\n",
            "[('and', 'CC')]\n",
            "[('Natural', 'JJ')]\n",
            "[('Language', 'NN')]\n",
            "[('processing', 'NN')]\n"
          ]
        }
      ]
    }
  ]
}